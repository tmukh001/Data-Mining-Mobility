{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550171ea-4564-43f4-86a1-dc15c1c8c056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: trackintel in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (1.3.1)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from trackintel) (2.0.3)\n",
      "Requirement already satisfied: geopandas>=0.12.0 in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (from trackintel) (0.14.4)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from trackintel) (3.7.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from trackintel) (1.24.3)\n",
      "Requirement already satisfied: shapely in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (from trackintel) (2.0.6)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from trackintel) (3.1)\n",
      "Requirement already satisfied: geoalchemy2 in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (from trackintel) (0.16.0)\n",
      "Requirement already satisfied: osmnx in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (from trackintel) (1.9.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from trackintel) (1.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from trackintel) (4.65.0)\n",
      "Requirement already satisfied: similaritymeasures in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (from trackintel) (1.2.0)\n",
      "Requirement already satisfied: fiona>=1.8.21 in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (from geopandas>=0.12.0->trackintel) (1.10.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from geopandas>=0.12.0->trackintel) (23.1)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (from geopandas>=0.12.0->trackintel) (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->trackintel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->trackintel) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->trackintel) (2023.3)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from geoalchemy2->trackintel) (1.4.39)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->trackintel) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->trackintel) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->trackintel) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->trackintel) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->trackintel) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->trackintel) (3.0.9)\n",
      "Requirement already satisfied: requests<2.33,>=2.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from osmnx->trackintel) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->trackintel) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->trackintel) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->trackintel) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->trackintel) (0.4.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas>=0.12.0->trackintel) (23.1.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas>=0.12.0->trackintel) (2024.8.30)\n",
      "Requirement already satisfied: click~=8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas>=0.12.0->trackintel) (8.0.4)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (from fiona>=1.8.21->geopandas>=0.12.0->trackintel) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\isaac\\appdata\\roaming\\python\\python311\\site-packages (from fiona>=1.8.21->geopandas>=0.12.0->trackintel) (0.7.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->trackintel) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.33,>=2.27->osmnx->trackintel) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.33,>=2.27->osmnx->trackintel) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.33,>=2.27->osmnx->trackintel) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4->geoalchemy2->trackintel) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install trackintel\n",
    "import pandas as pd\n",
    "import trackintel as ti\n",
    "import gzip\n",
    "import geopandas as gpd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d756e3f-8394-48f6-8d97-debb76e4091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {\n",
    "    'city_a': \"./cityA_groundtruthdata.csv.gz\",\n",
    "    'city_b': \"./cityB_challengedata.csv.gz\",\n",
    "    'city_c': \"./cityC_challengedata.csv.gz\",\n",
    "    'city_d': \"./cityD_challengedata.csv.gz\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919be7b0-f353-45d1-865c-89c00d35a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and decompress .gz files into a DataFrame\n",
    "def load_compressed_csv(file_path):\n",
    "    with gzip.open(file_path, 'rt') as gz_file:\n",
    "        return pd.read_csv(gz_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac9b808a-fd88-4624-a116-ba471d2e0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and preprocess the data\n",
    "def process_city_data(city_key):\n",
    "    # Load data from compressed file\n",
    "    print(f\"Loading data for {city_key}...\")\n",
    "    df = load_compressed_csv(data_paths[city_key])\n",
    "\n",
    "    # Remove rows with invalid coordinates (-999)\n",
    "    print(\"Cleaning data...\")\n",
    "    valid_data = df[(df['x'] != -999) & (df['y'] != -999)].copy()\n",
    "\n",
    "    # Combine date ('d') and time ('t') into a 'tracked_at' datetime column\n",
    "    valid_data['date'] = pd.to_datetime(valid_data['d'], format='%j', errors='coerce')\n",
    "    valid_data['time_offset'] = pd.to_timedelta(valid_data['t'] * 30, unit='m')\n",
    "    valid_data['tracked_at'] = valid_data['date'] + valid_data['time_offset']\n",
    "    valid_data['tracked_at'] = valid_data['tracked_at'].dt.tz_localize('UTC')\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    valid_data.drop(columns=['date', 'time_offset'], inplace=True)\n",
    "\n",
    "    # Rename columns for consistency\n",
    "    valid_data.rename(columns={'uid': 'user_id', 'x': 'longitude', 'y': 'latitude'}, inplace=True)\n",
    "\n",
    "    # Filter data to only include the first 30 days (first month)\n",
    "    print(\"Filtering data for the first 30 days...\")\n",
    "    start_date = valid_data['tracked_at'].min()  # Get the earliest date in the data\n",
    "    end_date = start_date + pd.Timedelta(days=30)  # Set the cutoff for 30 days after the start date\n",
    "    valid_data = valid_data[(valid_data['tracked_at'] >= start_date) & (valid_data['tracked_at'] < end_date)]\n",
    "\n",
    "    # Save cleaned data\n",
    "    output_file = Path(f\"processed_data_{city_key}.csv\")\n",
    "    valid_data.to_csv(output_file, index=False)\n",
    "    print(f\"Processed data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc35ade-a47f-4b73-af85-299dbf6b892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write triplegs data to a CSV file\n",
    "def export_triplegs_to_csv(triplegs, output_file, **kwargs):\n",
    "    \"\"\"Exports triplegs as WKT format to a CSV file.\"\"\"\n",
    "    triplegs_df = triplegs.to_wkt(rounding_precision=-1, trim=False)\n",
    "    triplegs_df.to_csv(output_file, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9392aad7-89e3-469a-a8c5-7b2a5591396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess data and generate triplegs\n",
    "def create_triplegs(city_key):\n",
    "    # Preprocess data\n",
    "    process_city_data(city_key)\n",
    "\n",
    "    # Load preprocessed data into positionfixes\n",
    "    preprocessed_file = Path(f\"processed_data_{city_key}.csv\")\n",
    "    print(f\"Reading preprocessed data for {city_key}...\")\n",
    "    positionfixes = ti.read_positionfixes_csv(preprocessed_file)\n",
    "\n",
    "    # Generate staypoints from positionfixes\n",
    "    print(\"Identifying staypoints...\")\n",
    "    positionfixes, staypoints = positionfixes.as_positionfixes.generate_staypoints(\n",
    "        method='sliding',\n",
    "        dist_threshold=1,         # Distance threshold in meters\n",
    "        time_threshold=90,        # Time threshold in minutes\n",
    "        gap_threshold=300,        # Gap threshold in minutes\n",
    "        distance_metric='haversine',\n",
    "        include_last=True,\n",
    "        exclude_duplicate_pfs=True,\n",
    "        print_progress=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Generate triplegs between staypoints\n",
    "    print(\"Generating triplegs...\")\n",
    "    positionfixes, triplegs = ti.preprocessing.generate_triplegs(\n",
    "        positionfixes, staypoints, method='between_staypoints', gap_threshold=90\n",
    "    )\n",
    "\n",
    "    # Export triplegs to CSV\n",
    "    triplegs_file = Path(f\"triplegs_{city_key}.csv\")\n",
    "    export_triplegs_to_csv(triplegs, triplegs_file, index=False)\n",
    "    print(f\"Triplegs exported to {triplegs_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b1938d-8e51-44f1-8a06-4a05da9d359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for city_b...\n",
      "Cleaning data...\n",
      "Filtering data for the first 30 days...\n",
      "Processed data saved to processed_data_city_b.csv\n",
      "Reading preprocessed data for city_b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Roaming\\Python\\Python311\\site-packages\\trackintel\\io\\util.py:13: UserWarning: Assuming default index as unique identifier. Pass 'index_col=None' as explicit argument to avoid a warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying staypoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 24906/24906 [05:12<00:00, 79.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating triplegs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Roaming\\Python\\Python311\\site-packages\\trackintel\\preprocessing\\positionfixes.py:573: UserWarning: The positionfixes with ids [    156     157     707 ... 9808937 9808938 9808939] lead to invalid tripleg geometries. The resulting triplegs were omitted and the tripleg id of the positionfixes was set to nan\n",
      "  warnings.warn(warn_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplegs exported to triplegs_city_b.csv\n"
     ]
    }
   ],
   "source": [
    "create_triplegs('city_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9676e493-f6bb-479b-9020-650da6b778fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from shapely.wkt import loads\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Step 1: Extract coordinates from LINESTRING using shapely\n",
    "def extract_coordinates_from_linestring(linestring):\n",
    "    \"\"\"\n",
    "    Extract coordinates from a LINESTRING WKT.\n",
    "    \"\"\"\n",
    "    geometry = loads(linestring)  # Parse the WKT string into a geometry object using shapely\n",
    "    return list(geometry.coords)   # Extract the coordinates as a list of (x, y) tuples\n",
    "\n",
    "# Step 2: Load and preprocess the triplegs data\n",
    "def get_tripleg_sequences(triplegs_file):\n",
    "    \"\"\"\n",
    "    Extracts the tripleg sequences from the triplegs CSV file by parsing the LINESTRING column.\n",
    "    Each row contains a trip, and each trip is a sequence of coordinates.\n",
    "    \"\"\"\n",
    "    # Read the triplegs CSV file into a pandas DataFrame\n",
    "    triplegs = pd.read_csv(triplegs_file)\n",
    "\n",
    "    sequences = []\n",
    "    for _, row in triplegs.iterrows():\n",
    "        # Extract coordinates from the LINESTRING column\n",
    "        coordinates = extract_coordinates_from_linestring(row['geom'])\n",
    "        sequences.append(coordinates)  # Each tripleg becomes a sequence of (x, y) pairs\n",
    "    return sequences\n",
    "\n",
    "# Step 3: Implement the GSP algorithm to mine sequential patterns\n",
    "def gsp_mine_sequential_patterns(sequences, min_support, max_pattern_length):\n",
    "    \"\"\"\n",
    "    Mines frequent sequential patterns using the Generalized Sequential Pattern (GSP) algorithm.\n",
    "    \"\"\"\n",
    "    num_sequences = len(sequences)\n",
    "    \n",
    "    # Step 3.1: Generate frequent patterns of length 1 (individual (x, y) coordinates)\n",
    "    item_counts = defaultdict(int)\n",
    "    for sequence in sequences:\n",
    "        for item in sequence:\n",
    "            item_counts[item] += 1\n",
    "\n",
    "    # Step 3.2: Create the list of frequent patterns (length-1 sequences)\n",
    "    frequent_patterns = {1: []}\n",
    "    for item, count in item_counts.items():\n",
    "        support = count / num_sequences\n",
    "        if support >= min_support:\n",
    "            frequent_patterns[1].append((item, support))\n",
    "\n",
    "    # Step 3.3: Generate patterns of length 2, 3, ..., max_pattern_length\n",
    "    for length in range(2, max_pattern_length + 1):\n",
    "        candidates = generate_candidates(frequent_patterns[length - 1], length)\n",
    "        candidate_counts = defaultdict(int)\n",
    "\n",
    "        # Count support for each candidate sequence\n",
    "        for sequence in sequences:\n",
    "            for candidate in candidates:\n",
    "                if is_subsequence(candidate, sequence):\n",
    "                    candidate_counts[candidate] += 1\n",
    "\n",
    "        # Store frequent patterns of the current length\n",
    "        frequent_patterns[length] = []\n",
    "        for candidate, count in candidate_counts.items():\n",
    "            support = count / num_sequences\n",
    "            if support >= min_support:\n",
    "                frequent_patterns[length].append((candidate, support))\n",
    "\n",
    "        # If no frequent patterns were found for this length, stop\n",
    "        if len(frequent_patterns[length]) == 0:\n",
    "            break\n",
    "\n",
    "    return frequent_patterns\n",
    "\n",
    "# Helper function to generate candidate sequences from frequent patterns\n",
    "def generate_candidates(frequent_patterns, length):\n",
    "    \"\"\"\n",
    "    Generate candidate sequences of a given length from the frequent patterns of the previous length.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    for i in range(len(frequent_patterns)):\n",
    "        for j in range(i, len(frequent_patterns)):\n",
    "            candidate = list(frequent_patterns[i]) + list(frequent_patterns[j][1:])\n",
    "            candidates.append(tuple(candidate))\n",
    "    return candidates\n",
    "\n",
    "# Helper function to check if a pattern is a subsequence of a sequence\n",
    "def is_subsequence(pattern, sequence):\n",
    "    \"\"\"\n",
    "    Check if a given pattern is a subsequence of a sequence.\n",
    "    \"\"\"\n",
    "    it = iter(sequence)\n",
    "    return all(item in it for item in pattern)\n",
    "\n",
    "# Step 4: Export the frequent patterns to a file\n",
    "def export_frequent_patterns(frequent_patterns, output_file):\n",
    "    \"\"\"\n",
    "    Export the frequent patterns to a CSV file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        for length, patterns in frequent_patterns.items():\n",
    "            f.write(f\"Length-{length} Patterns:\\n\")\n",
    "            for pattern, support in patterns:\n",
    "                f.write(f\"{pattern}: {support:.4f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Step 5: Main function to run the process and mine patterns\n",
    "def create_and_mine_triplegs(city_key, min_support, max_pattern_length):\n",
    "    \"\"\"\n",
    "    Main function to process the tripleg data, mine sequential patterns, and export results.\n",
    "    \"\"\"\n",
    "    # Path to the triplegs file generated by your `create_triplegs` function\n",
    "    triplegs_file = Path(f\"triplegs_{city_key}.csv\")\n",
    "    \n",
    "    # Step 1: Convert triplegs to sequences of (x, y) pairs\n",
    "    sequences = get_tripleg_sequences(triplegs_file)\n",
    "    \n",
    "    # Step 2: Run the GSP algorithm to find frequent patterns\n",
    "    frequent_patterns = gsp_mine_sequential_patterns(sequences, min_support, max_pattern_length)\n",
    "    print(frequent_patterns)\n",
    "    # Step 3: Export the frequent patterns to a file\n",
    "    export_frequent_patterns(frequent_patterns, f\"frequent_patterns_{city_key}.csv\")\n",
    "    print(f\"Frequent patterns have been saved to 'frequent_patterns_{city_key}.csv'.\")\n",
    "\n",
    "# Example usage\n",
    "city_key = 'city_b'  # Example city key\n",
    "# create_and_mine_triplegs(city_key, min_support=0.1, max_pattern_length=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf77e9c9-707a-41b8-9977-9671e8119697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "triplegs_file = Path(f\"triplegs_{city_key}.csv\")\n",
    "    \n",
    "# Convert triplegs to sequences of (x, y) pairs\n",
    "\n",
    "sequences = get_tripleg_sequences(triplegs_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c43ae5d-60d5-476f-9f8b-01d34119537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_sequences_to_csv(sequences, filename):\n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for seq in sequences:\n",
    "            # Flatten the sequence into individual pairs and write to CSV\n",
    "            writer.writerow([f'({x[0]},{x[1]})' for x in seq])\n",
    "\n",
    "# Example usage:\n",
    "save_sequences_to_csv(sequences, 'sequences_b.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40425d81-df16-40d6-9049-edb53ac9406e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b377f-dabf-4b96-bd0b-1f514fb7b79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168478c-b054-422e-b366-f242a74f564f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c51650-6160-490b-ae05-4c07ddcf02df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c1459-b030-4722-9017-1dacc2f323f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970a6ad-ffea-4747-ad45-375ed148ce8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b2e5f9-fe49-4fe9-8122-0227a369ef10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
